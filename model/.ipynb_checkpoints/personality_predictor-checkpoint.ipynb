{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10b27ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04297f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "py.init_notebook_mode(connected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "594d3cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"mbti_1.csv\")\n",
    "us = pd.read_csv('Users.csv')\n",
    "ps = pd.read_csv('ForumMessages.csv')\n",
    "mbti = {'I':\"Introversion\",\"E\":\"Extroversion\", \"N\":\"Intutions\",\"S\":\"Sensing\",\"T\":\"Thinking\",\"F\":\"Feeling\",\"J\":\"Judging\",\"P\":\"Perceiving\"}\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a625e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Id  ForumTopicId  PostUserId             PostDate   \n",
      "0              1             1         478  04/28/2010 23:13:08  \\\n",
      "1              2             2         606  04/29/2010 15:48:46   \n",
      "2              3             2         478  04/29/2010 15:48:46   \n",
      "3              4             2         368  04/29/2010 15:48:46   \n",
      "4             14             7         478  05/02/2010 14:37:35   \n",
      "...          ...           ...         ...                  ...   \n",
      "2094623  2485115        446240    16931977  10/17/2023 00:29:23   \n",
      "2094624  2485116        433121     3490494  10/17/2023 00:29:57   \n",
      "2094625  2485118        278668     3490494  10/17/2023 00:32:15   \n",
      "2094626  2485119        444161    17016966  10/17/2023 00:32:43   \n",
      "2094627  2485120        447648     9609342  10/17/2023 00:34:37   \n",
      "\n",
      "         ReplyToForumMessageId   \n",
      "0                          NaN  \\\n",
      "1                          NaN   \n",
      "2                          NaN   \n",
      "3                          NaN   \n",
      "4                          NaN   \n",
      "...                        ...   \n",
      "2094623              2476787.0   \n",
      "2094624              2478924.0   \n",
      "2094625              2477770.0   \n",
      "2094626              2484333.0   \n",
      "2094627              2484917.0   \n",
      "\n",
      "                                                   Message  Medal   \n",
      "0        <div>In response to a comment on the No Free H...    NaN  \\\n",
      "1        Hi, I'm interested in participating in the con...    NaN   \n",
      "2        Tanya,<div><br></div><div>Good to hear from yo...    NaN   \n",
      "3        Hi Tanya, <br><br>Kaggle will maintain a ratin...    NaN   \n",
      "4        Now that we have a handful of algorithms that ...    NaN   \n",
      "...                                                    ...    ...   \n",
      "2094623  <p>Congratulations!<br>\\nAnd I think that is t...    NaN   \n",
      "2094624  <p>Thank you very much for the comment ðŸ˜ŽðŸ‘Š! I'm...    NaN   \n",
      "2094625  <p>Thank you very much for your supportive com...    NaN   \n",
      "2094626                 <p>Okay, thanks for the reply.</p>    NaN   \n",
      "2094627  <p>Thanks a lot for your reply! Looking forwar...    NaN   \n",
      "\n",
      "        MedalAwardDate  \n",
      "0                  NaN  \n",
      "1                  NaN  \n",
      "2                  NaN  \n",
      "3                  NaN  \n",
      "4                  NaN  \n",
      "...                ...  \n",
      "2094623            NaN  \n",
      "2094624            NaN  \n",
      "2094625            NaN  \n",
      "2094626            NaN  \n",
      "2094627            NaN  \n",
      "\n",
      "[2094628 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8e3ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt_srs = train['type'].value_counts()\n",
    "# cnt_srs = [cnt_srs.index, cnt_srs.values]\n",
    "# plt.figure(figsize=(12,4))\n",
    "# sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\n",
    "# sns.barplot(train['type'])\n",
    "# plt.ylabel('number of occurences', fontsize=13)\n",
    "# plt.xlabel('types',fontsize=13)\n",
    "# plt.show()\n",
    "# # print(cnt_srs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfcf5322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PostUserId                                            Message\n",
      "0               62  tes David, just a quick note to say thanks for...\n",
      "1              368  Hi Tanya, <br><br>Kaggle will maintain a ratin...\n",
      "2              381  <p>Hi Sergei,</p>\\r\\n<p>Compiled Matlab p-code...\n",
      "3              387  <p>From an economic perspective let's look at ...\n",
      "4              389  <p>There's still one more confusion.. what doe...\n",
      "...            ...                                                ...\n",
      "337795    17254990                            <p>Hi everyone!! :)</p>\n",
      "337796    17255109                     <p>Its very good so useful</p>\n",
      "337797    17256383  <p>Excellent EDA work with wide range of chart...\n",
      "337798    17257536                        <p>be patient good luck</p>\n",
      "337799    17258439                               <p>Good content </p>\n",
      "\n",
      "[337800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "ps['Message'] = ps['Message'].fillna('')\n",
    "ps_join = ps.groupby('PostUserId')['Message'].agg(lambda col: ' '.join(col)).reset_index()\n",
    "print(ps_join)\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators = 20, max_depth = 4, n_jobs = -1)\n",
    "tfidfi = TfidfVectorizer(ngram_range = (1,1), stop_words='english')\n",
    "tsvd = TruncatedSVD(n_components = 10)\n",
    "model = Pipeline([('tifidfi', tfidfi),('tsvd1', tsvd),('etc',etc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6b229aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "np.random.seed(1)\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'neg_log_loss':'neg_log_loss',\n",
    "           'f1_micro':'f1_micro'}\n",
    "results = cross_validate(model, train['posts'], train['type'], cv=kfolds, scoring = scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "936f5259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.2818(+/- 0.0166)\n",
      "CV F1: 0.2818(+/- 0.0166)\n",
      "CV Logloss: -2.1509(+/- 0.0147)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f}(+/- {:0.4f})\".format(np.mean(results['test_acc']),np.std(results['test_acc'])))\n",
    "print(\"CV F1: {:0.4f}(+/- {:0.4f})\".format(np.mean(results['test_f1_micro']),np.std(results['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f}(+/- {:0.4f})\".format(np.mean(results['test_neg_log_loss']),np.std(results['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14090213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "  text = BeautifulSoup(text,'lxml').text\n",
    "  text = re.sub(r'\\|\\|\\|',r'',text)\n",
    "  text = re.sub(r'http\\S+',r'<URL>',text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2cb531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.indexing._iLocIndexer object at 0x000001CABEC09590>\n"
     ]
    }
   ],
   "source": [
    "train['clean_posts'] = train['posts'].apply(cleanText)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "390a1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "tfidf2 = CountVectorizer(ngram_range=(1,1), stop_words='english',lowercase=True,max_features=5000)\n",
    "\n",
    "model_np = Pipeline([('tfidf1',tfidf2), (\"nb\", MultinomialNB())])\n",
    "\n",
    "results_nb = cross_validate(model_np, train['clean_posts'], train['type'], cv=kfolds, scoring=scoring, n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc62bd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.5627(+/- 0.0110)\n",
      "CV F1: 0.5627(+/- 0.0110)\n",
      "CV Logloss: 6.2055(+/- 0.3766)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f}(+/- {:0.4f})\".format(np.mean(results_nb['test_acc']),np.std(results_nb['test_acc'])))\n",
    "print(\"CV F1: {:0.4f}(+/- {:0.4f})\".format(np.mean(results_nb['test_f1_micro']),np.std(results_nb['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f}(+/- {:0.4f})\".format(np.mean(-1*results_nb['test_neg_log_loss']),np.std(results_nb['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c2b075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "tfidf2 = CountVectorizer(ngram_range=(1,1), stop_words='english',lowercase=True,max_features=5000)\n",
    "\n",
    "model_lr = Pipeline([('tfidf1',tfidf2), (\"lr\", LogisticRegression(class_weight=\"balanced\",C=0.005))])\n",
    "\n",
    "results_lr = cross_validate(model_lr, train['clean_posts'], train['type'], cv=kfolds, scoring=scoring, n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "618756df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.6561(+/- 0.0138)\n",
      "CV F1: 0.6561(+/- 0.0138)\n",
      "CV Logloss: 1.3072(+/- 0.0131)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f}(+/- {:0.4f})\".format(np.mean(results_lr['test_acc']),np.std(results_lr['test_acc'])))\n",
    "print(\"CV F1: {:0.4f}(+/- {:0.4f})\".format(np.mean(results_lr['test_f1_micro']),np.std(results_lr['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f}(+/- {:0.4f})\".format(np.mean(-1*results_lr['test_neg_log_loss']),np.std(results_lr['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58aa362b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m train_sizes, train_scores , test_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m----> 2\u001b[0m   \u001b[43mlearning_curve\u001b[49m(model_lr, train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_posts\u001b[39m\u001b[38;5;124m'\u001b[39m], train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m], cv \u001b[38;5;241m=\u001b[39m kfolds, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      3\u001b[0m                  scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m'\u001b[39m,train_sizes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m.1\u001b[39m,\u001b[38;5;241m1.0\u001b[39m,\u001b[38;5;241m10\u001b[39m),random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'learning_curve' is not defined"
     ]
    }
   ],
   "source": [
    "train_sizes, train_scores , test_scores = \\\n",
    "  learning_curve(model_lr, train['clean_posts'], train['type'], cv = kfolds, n_jobs=-1,\n",
    "                 scoring='f1_micro',train_sizes = np.linspace(.1,1.0,10),random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3625aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(X,y, train_sizes, train_scores, test_scores, title='', ylim=None, figsize=(14,8)):\n",
    "  plt.figure(figsize=figsize)\n",
    "  plt.title(title)\n",
    "  if ylim is not None:\n",
    "    plt.ylim(*ylim)\n",
    "  plt.xlabel(\"Training examples\")\n",
    "  plt.ylabel(\"Score\")\n",
    "\n",
    "  train_scores_mean = np.mean(train_scores, axis = 1)\n",
    "  train_scores_std = np.std(train_scores, axis=1)\n",
    "  test_scores_mean = np.mean(test_scores, axis=1)\n",
    "  test_scores_std = np.sd(test_scores, axis=1)\n",
    "  plt.grid()\n",
    "\n",
    "  plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "  plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "  plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "  plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Training score\")\n",
    "\n",
    "  plt.legend(loc=\"best\")\n",
    "  return plt\n",
    "plot_learning_curve(train['posts'], train['type'], train_sizes, train_scores, test_scores, ylim=(0.1, 1.01), figsize=(13,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9149aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sujal Gupta\\AppData\\Local\\Temp\\ipykernel_2828\\496569971.py:2: MarkupResemblesLocatorWarning:\n",
      "\n",
      "The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "\n",
      "C:\\Users\\Sujal Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ps_join[\"clean_comments\"] = ps_join[\"Message\"].apply(cleanText)\n",
    "model_lr.fit(train['clean_posts'], train['type'])\n",
    "pred_all = model_lr.predict(ps_join['clean_comments'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc2088a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   personality   count\n",
      "5         ESFP  182404\n",
      "10        INTJ   80880\n",
      "3         ENTP   18528\n",
      "14        ISTJ   14493\n",
      "2         ENTJ   14123\n",
      "11        INTP    6002\n",
      "12        ISFJ    5744\n",
      "13        ISFP    5652\n",
      "15        ISTP    4627\n",
      "4         ESFJ    1487\n",
      "0         ENFJ    1363\n",
      "1         ENFP     911\n",
      "6         ESTJ     623\n",
      "9         INFP     379\n",
      "8         INFJ     311\n",
      "7         ESTP     273\n"
     ]
    }
   ],
   "source": [
    "cnt_all = np.unique(pred_all, return_counts=True)\n",
    "pred_df = pd.DataFrame({'personality': cnt_all[0],'count': cnt_all[1]}, columns=['personality', 'count'], index=None)\n",
    "pred_df.sort_values('count', ascending=False, inplace=True)\n",
    "print(pred_df)\n",
    "# plt.figure(figsize=(12,6))\n",
    "# sns.barplot(pred_df['personality'], pred_df['count'], alpha = 0.8)\n",
    "# plt.ylabel('Numbeer of Occurences', fontsize=12)\n",
    "# plt.xlabel('Personality', fontsize=12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bcda52a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   personality   count   percent                                 description\n",
      "5         ESFP  182404  0.539976     Extroversion Sensing Feeling Perceiving\n",
      "10        INTJ   80880  0.239432     Introversion Intutions Thinking Judging\n",
      "3         ENTP   18528  0.054849  Extroversion Intutions Thinking Perceiving\n",
      "14        ISTJ   14493  0.042904       Introversion Sensing Thinking Judging\n",
      "2         ENTJ   14123  0.041809     Extroversion Intutions Thinking Judging\n",
      "11        INTP    6002  0.017768  Introversion Intutions Thinking Perceiving\n",
      "12        ISFJ    5744  0.017004        Introversion Sensing Feeling Judging\n",
      "13        ISFP    5652  0.016732     Introversion Sensing Feeling Perceiving\n",
      "15        ISTP    4627  0.013697    Introversion Sensing Thinking Perceiving\n",
      "4         ESFJ    1487  0.004402        Extroversion Sensing Feeling Judging\n",
      "0         ENFJ    1363  0.004035      Extroversion Intutions Feeling Judging\n",
      "1         ENFP     911  0.002697   Extroversion Intutions Feeling Perceiving\n",
      "6         ESTJ     623  0.001844       Extroversion Sensing Thinking Judging\n",
      "9         INFP     379  0.001122   Introversion Intutions Feeling Perceiving\n",
      "8         INFJ     311  0.000921      Introversion Intutions Feeling Judging\n",
      "7         ESTP     273  0.000808    Extroversion Sensing Thinking Perceiving\n"
     ]
    }
   ],
   "source": [
    "pred_df['percent'] = pred_df['count']/pred_df['count'].sum()\n",
    "pred_df['description'] = pred_df['personality'].apply(lambda x: ' '.join([mbti[l] for l in list(x)]))\n",
    "print(pred_df)\n",
    "\n",
    "# labels = pred_df['description']\n",
    "# sizes = pred_df['percent'] * 100\n",
    "\n",
    "# trace = go.Pie(labels = labels, values= sizes)\n",
    "# layout = go.Layout( title = \"kaggle user personality distribution\")\n",
    "\n",
    "# data = [trace]\n",
    "# fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "# py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca006ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "063f9126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./personality_predictor.joblib']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model_lr,'./personality_predictor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888d38a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
